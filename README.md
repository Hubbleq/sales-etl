# âœ¦ Sales Analytics Pipeline

Pipeline completo de anÃ¡lise de vendas com **ETL**, **API REST** e **Dashboard interativo**.

## Tecnologias

| Camada | Tecnologia |
|--------|-----------|
| ETL | Python, Pandas |
| API | FastAPI, Uvicorn |
| Dashboard | Streamlit, Plotly |
| Banco de Dados | PostgreSQL (Supabase) |
| ORM | SQLAlchemy |

## Estrutura do Projeto

```
etl-sales/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ db.py            # ConexÃ£o com o banco
â”‚   â”‚   â”œâ”€â”€ main.py          # Endpoints da API (FastAPI)
â”‚   â”‚   â””â”€â”€ queries.py       # Queries SQL parametrizadas
â”‚   â”œâ”€â”€ etl/
â”‚   â”‚   â”œâ”€â”€ extract.py       # Leitura do CSV
â”‚   â”‚   â”œâ”€â”€ transform.py     # ValidaÃ§Ã£o e limpeza
â”‚   â”‚   â”œâ”€â”€ load.py          # Carga no banco
â”‚   â”‚   â””â”€â”€ run_etl.py       # Orquestrador do ETL
â”‚   â””â”€â”€ config.py            # VariÃ¡veis de ambiente
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ streamlit_app.py     # Dashboard premium com storytelling
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_sales.csv     # Dados de vendas (2025)
â”œâ”€â”€ generate_data.py         # Gerador de dados realistas
â”œâ”€â”€ schema.sql               # Schema do banco (modelo dimensional)
â”œâ”€â”€ requirements.txt         # DependÃªncias Python
â”œâ”€â”€ run.bat                  # Script para iniciar tudo (Windows)
â”œâ”€â”€ .env.example             # Modelo de variÃ¡veis de ambiente
â””â”€â”€ README.md
```

---

## ğŸš€ Passo a Passo para Rodar o Projeto

### PrÃ©-requisitos

- **Python 3.10+** instalado ([python.org](https://python.org))
- **Git** instalado ([git-scm.com](https://git-scm.com))
- **Conta no Supabase** com um projeto PostgreSQL ([supabase.com](https://supabase.com))

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/Hubbleq/sales-etl.git
cd sales-etl
```

### 2. Crie o ambiente virtual e instale as dependÃªncias

```bash
# Windows
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

```bash
# Linux / Mac
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 3. Configure o banco de dados

Copie o arquivo de exemplo e preencha com suas credenciais do Supabase:

```bash
copy .env.example .env        # Windows
# cp .env.example .env        # Linux/Mac
```

Edite o `.env`:

```env
DATABASE_URL=postgresql+psycopg://postgres:<PASSWORD>@db.<PROJECT_REF>.supabase.co:5432/postgres
```

### 4. Crie as tabelas no banco

Execute o script SQL no editor do Supabase (SQL Editor) ou via psql:

```bash
# O arquivo schema.sql contÃ©m as tabelas:
# dim_loja, dim_produto, fato_vendas, etl_execucoes
```

### 5. Execute o ETL (carga de dados)

```bash
python -m app.etl.run_etl
```

Isso irÃ¡ ler o `data/sample_sales.csv`, transformar e carregar no banco.

### 6. Inicie o sistema

#### âš¡ Jeito FÃ¡cil (Windows)

DÃª **dois cliques** no arquivo `run.bat` na raiz do projeto. Ele:
1. Fecha processos antigos nas portas
2. Inicia a **API** (backend) na porta 8001
3. Inicia o **Dashboard** (frontend) na porta 8501

#### Manual (qualquer OS)

Abra **dois terminais** na pasta do projeto:

**Terminal 1 â€” API:**
```bash
.venv\Scripts\activate
uvicorn app.api.main:app --reload --port 8001
```

**Terminal 2 â€” Dashboard:**
```bash
.venv\Scripts\activate
streamlit run dashboard/streamlit_app.py --server.port 8501
```

### 7. Acesse

| ServiÃ§o | URL |
|---------|-----|
| ğŸ“Š **Dashboard** | [http://localhost:8501](http://localhost:8501) |
| ğŸ”§ **API Docs** (Swagger) | [http://localhost:8001/docs](http://localhost:8001/docs) |
| â¤ï¸ **Health Check** | [http://localhost:8001/health](http://localhost:8001/health) |

---

## Endpoints da API

| MÃ©todo | Rota | DescriÃ§Ã£o |
|--------|------|-----------|
| GET | `/health` | Status da API |
| GET | `/sales/daily?start=...&end=...` | Receita diÃ¡ria |
| GET | `/sales/monthly?start=...&end=...` | Receita mensal |
| GET | `/products/top?start=...&end=...&limit=N` | Top N produtos |
| GET | `/products/categories?start=...&end=...` | Receita por categoria |
| GET | `/stores/performance?start=...&end=...` | Performance por loja |
| GET | `/stores/monthly?start=...&end=...` | Receita mensal por loja |
| GET | `/analysis/heatmap?start=...&end=...` | Dados Loja x Categoria |

## Schema do Banco (Modelo Dimensional)

- `dim_loja` â€” DimensÃ£o de lojas (nome, cidade, estado)
- `dim_produto` â€” DimensÃ£o de produtos (SKU, nome, categoria)
- `fato_vendas` â€” Fato de vendas (data, quantidade, preÃ§o, desconto, total)
- `etl_execucoes` â€” Log de execuÃ§Ãµes do ETL

## Dashboard

Design minimalista premium com storytelling de dados:

1. **VisÃ£o Geral** â€” KPIs com variaÃ§Ã£o mÃªs-a-mÃªs e insight narrativo automÃ¡tico
2. **TendÃªncias** â€” GrÃ¡fico de evoluÃ§Ã£o diÃ¡ria + mÃ©dia mÃ³vel 7 dias
3. **Categorias** â€” Donut chart com distribuiÃ§Ã£o percentual
4. **Rankings** â€” Top 10 produtos e performance por loja (barras HTML)
5. **EvoluÃ§Ã£o Mensal** â€” Comparativo multi-loja mÃªs a mÃªs
6. **Dados Detalhados** â€” Tabela com busca e ordenaÃ§Ã£o

## LicenÃ§a

MIT
